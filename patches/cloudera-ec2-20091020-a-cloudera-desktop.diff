diff --git a/hadoop-ec2-init-remote.sh b/hadoop-ec2-init-remote.sh
index 7842799..d19a355 100644
--- a/hadoop-ec2-init-remote.sh
+++ b/hadoop-ec2-init-remote.sh
@@ -1,5 +1,9 @@
 #!/bin/bash -x
-
+# 
+# Modified version of hadoop-ec2-init-remote.sh, customized to install
+# Cloudera Desktop.
+#
+#
 ################################################################################
 # Script that is run on each EC2 instance on boot. It is passed in the EC2 user
 # data, so should not exceed 16K in size after gzip compression.
@@ -22,8 +26,9 @@ else
   IS_MASTER=false
 fi
 
-REPO=${REPO:-stable}
-HADOOP=hadoop${HADOOP_VERSION:+-${HADOOP_VERSION}} # prefix with a dash if set
+# Force versions
+REPO="testing"
+HADOOP="hadoop-0.20"
 
 function register_auto_shutdown() {
   if [ ! -z "$AUTO_SHUTDOWN" ]; then
@@ -43,7 +48,7 @@ EOF
     cat > /etc/yum.repos.d/cloudera-$REPO.repo <<EOF
 [cloudera-$REPO]
 name=Cloudera's Distribution for Hadoop ($REPO)
-mirrorlist=http://archive.cloudera.com/redhat/cdh/$REPO/mirrors
+baseurl=http://archive.cloudera.com/redhat/cdh/$REPO/
 gpgkey = http://archive.cloudera.com/redhat/cdh/RPM-GPG-KEY-cloudera
 gpgcheck = 0
 EOF
@@ -427,6 +432,26 @@ function configure_hadoop() {
   <name>fs.s3n.awsSecretAccessKey</name>
   <value>$AWS_SECRET_ACCESS_KEY</value>
 </property>
+<!-- Start Cloudera Desktop -->
+<property>
+  <name>dfs.namenode.plugins</name>
+  <value>org.apache.hadoop.thriftfs.NamenodePlugin</value>
+  <description>Comma-separated list of namenode plug-ins to be activated.
+  </description>
+</property>
+<property>
+  <name>dfs.datanode.plugins</name>
+  <value>org.apache.hadoop.thriftfs.DatanodePlugin</value>
+  <description>Comma-separated list of datanode plug-ins to be activated.
+  </description>
+</property>
+<property>
+  <name>mapred.jobtracker.plugins</name>
+  <value>org.apache.hadoop.thriftfs.ThriftJobTrackerPlugin</value>
+  <description>Comma-separated list of jobtracker plug-ins to be activated.
+  </description>
+</property>
+<!-- End Cloudera Desktop -->
 </configuration>
 EOF
 
@@ -436,6 +461,14 @@ EOF
 </allocations>
 EOF
 
+  cat > /etc/$HADOOP/conf.dist/hadoop-metrics.properties <<EOF
+# Exposes /metrics URL endpoint for metrics information.
+dfs.class=org.apache.hadoop.metrics.spi.NoEmitMetricsContext
+mapred.class=org.apache.hadoop.metrics.spi.NoEmitMetricsContext
+jvm.class=org.apache.hadoop.metrics.spi.NoEmitMetricsContext
+rpc.class=org.apache.hadoop.metrics.spi.NoEmitMetricsContext
+EOF
+
   # Keep PID files in a non-temporary directory
   sed -i -e "s|# export HADOOP_PID_DIR=.*|export HADOOP_PID_DIR=/var/run/hadoop|" \
     /etc/$HADOOP/conf.dist/hadoop-env.sh
@@ -485,6 +518,7 @@ you may wish to use
 <ul>
 <li><a href="http://$MASTER_HOST:50070/">NameNode</a>
 <li><a href="http://$MASTER_HOST:50030/">JobTracker</a>
+<li><a href="http://$MASTER_HOST:8088/">Cloudera Desktop</a>
 </ul>
 </body>
 </html>
@@ -545,15 +579,55 @@ function start_hadoop_slave() {
   service $HADOOP-tasktracker start
 }
 
+function install_cloudera_desktop {
+  if which dpkg &> /dev/null; then
+    if $IS_MASTER; then
+      apt-get -y install libxslt1.1 cloudera-desktop cloudera-desktop-plugins
+      dpkg -i /tmp/cloudera-desktop.deb /tmp/cloudera-desktop-plugins.deb
+    else
+      apt-get -y install cloudera-desktop-plugins
+      dpkg -i /tmp/cloudera-desktop-plugins.deb
+    fi
+  elif which rpm &> /dev/null; then
+    if $IS_MASTER; then
+      yum install -y python-devel cloudera-desktop cloudera-desktop-plugins
+    else
+      yum install -y cloudera-desktop-plugins
+    fi
+  fi
+}
+
+function configure_cloudera_desktop {
+  if $IS_MASTER; then
+    mv /usr/share/cloudera-desktop/conf/cloudera-desktop.ini /usr/share/cloudera-desktop/conf/cloudera-desktop.ini.orig
+    cat > /usr/share/cloudera-desktop/conf/cloudera-desktop.ini <<EOF
+[hadoop]
+[[hdfs_clusters]]
+[[[default]]]
+namenode_host=$MASTER_HOST
+[[mapred_clusters]]
+[[[default]]]
+jobtracker_host=$MASTER_HOST
+EOF
+  fi      
+}
+
+function start_cloudera_desktop {
+  /etc/init.d/cloudera-desktop start
+}
+
 register_auto_shutdown
 update_repo
 install_user_packages
 install_hadoop
+install_cloudera_desktop
 configure_hadoop
+configure_cloudera_desktop
 
 if $IS_MASTER ; then
   setup_web
   start_hadoop_master
+  start_cloudera_desktop
 else
   start_hadoop_slave
 fi
